{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction before training : f(5)=0.0\n",
      "epoch 1/10, loss=30.0, w=1.2\n",
      "epoch 3/10, loss=0.7680001854896545, w=1.871999988555908\n",
      "epoch 5/10, loss=0.019660834223031998, w=1.9795200133323667\n",
      "epoch 7/10, loss=0.0005033080233260989, w=1.9967231869697568\n",
      "epoch 9/10, loss=1.2884394891443662e-05, w=1.999475698471069\n",
      "prediction after training : f(5)=10.0\n"
     ]
    }
   ],
   "source": [
    "# f=w*x\n",
    "#f=2*x\n",
    "X=np.array([1,2,3,4],dtype=np.float32)\n",
    "y=np.array([2,4,6,8],dtype=np.float32)\n",
    "w=0.0\n",
    "\n",
    "#model prediction\n",
    "\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "def loss(y,y_predicted):\n",
    "    return ((y_predicted-y)**2).mean()\n",
    "\n",
    "#gradient\n",
    "\n",
    "def gradient(x,y,y_predicted):\n",
    "    return np.dot(2*x,y_predicted-y).mean()\n",
    "  \n",
    "\n",
    "\n",
    "print(f'prediction before training : f(5)={forward(5)}')\n",
    "#Training\n",
    "lr=0.01\n",
    "n_iters=10\n",
    "for epoch in range(n_iters):\n",
    "    #prediction\n",
    "    y_predicted=forward(X)\n",
    "    #loss\n",
    "    l=loss(y,y_predicted)\n",
    "    #gradient\n",
    "    dw=gradient(X,y,y_predicted)\n",
    "    #update weight\n",
    "    w-=lr*dw\n",
    "    if epoch%2==0:\n",
    "        print(f'epoch {epoch+1}/{n_iters}, loss={l}, w={w}')\n",
    "print(f'prediction after training : f(5)={forward(5):.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction before training : f(5)=0.0\n",
      "epoch 1/50, loss=30.0, w=0.29999998211860657\n",
      "epoch 3/50, loss=15.660187721252441, w=0.7717499136924744\n",
      "epoch 5/50, loss=8.17471694946289, w=1.1125893592834473\n",
      "epoch 7/50, loss=4.2672529220581055, w=1.358845829963684\n",
      "epoch 9/50, loss=2.227532148361206, w=1.5367661714553833\n",
      "epoch 11/50, loss=1.1627856492996216, w=1.6653136014938354\n",
      "epoch 13/50, loss=0.6069811582565308, w=1.758189082145691\n",
      "epoch 15/50, loss=0.3168478012084961, w=1.825291633605957\n",
      "epoch 17/50, loss=0.1653965264558792, w=1.873773217201233\n",
      "epoch 19/50, loss=0.08633805811405182, w=1.9088011980056763\n",
      "epoch 21/50, loss=0.0450688973069191, w=1.934108853340149\n",
      "epoch 23/50, loss=0.02352631464600563, w=1.952393651008606\n",
      "epoch 25/50, loss=0.012280836701393127, w=1.9656044244766235\n",
      "epoch 27/50, loss=0.0064106592908501625, w=1.9751492738723755\n",
      "epoch 29/50, loss=0.0033464201260358095, w=1.982045292854309\n",
      "epoch 31/50, loss=0.0017468547448515892, w=1.987027645111084\n",
      "epoch 33/50, loss=0.0009118800517171621, w=1.9906275272369385\n",
      "epoch 35/50, loss=0.0004760062729474157, w=1.9932283163070679\n",
      "epoch 37/50, loss=0.0002484779979567975, w=1.9951075315475464\n",
      "epoch 39/50, loss=0.00012970640091225505, w=1.9964652061462402\n",
      "epoch 41/50, loss=6.770494655938819e-05, w=1.9974461793899536\n",
      "epoch 43/50, loss=3.5343608033144847e-05, w=1.998154878616333\n",
      "epoch 45/50, loss=1.844714643084444e-05, w=1.9986668825149536\n",
      "epoch 47/50, loss=9.631531611375976e-06, w=1.9990367889404297\n",
      "epoch 49/50, loss=5.027383849665057e-06, w=1.9993040561676025\n",
      "prediction after training : f(5)=10.0\n"
     ]
    }
   ],
   "source": [
    "#replacing gradient calculation \n",
    "# f=w*x\n",
    "#f=2*x\n",
    "import torch\n",
    "X=torch.tensor([1,2,3,4],dtype=torch.float32)\n",
    "y=torch.tensor([2,4,6,8],dtype=torch.float32)\n",
    "w=torch.tensor(0.0,dtype=torch.float32,requires_grad=True)\n",
    "\n",
    "#model prediction\n",
    "\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "def loss(y,y_predicted):\n",
    "    return ((y_predicted-y)**2).mean()\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "print(f'prediction before training : f(5)={forward(5)}')\n",
    "#Training\n",
    "lr=0.01\n",
    "n_iters=50\n",
    "for epoch in range(n_iters):\n",
    "    #prediction\n",
    "    y_predicted=forward(X)\n",
    "    #loss\n",
    "    l=loss(y,y_predicted)\n",
    "    #gradient=backwardpass \n",
    "    l.backward()\n",
    "    #update weights\n",
    "    with torch.no_grad():\n",
    "        w-=lr*w.grad\n",
    "    w.grad.zero_()  # zero the gradients after updating weights to avoid accumulation of gradients from previous epoch  # important for the next epoch.\n",
    "\n",
    "    if epoch%2==0:\n",
    "        print(f'epoch {epoch+1}/{n_iters}, loss={l}, w={w}')\n",
    "print(f'prediction after training : f(5)={forward(5):.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 . Design our model (input,ouput_size,foward_pass)\n",
    "#2. Construct Loss and optimizer\n",
    "#3. Training Loop\n",
    "# -Forward Pass \n",
    "# -Backward Pass \n",
    "# -update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction before training : f(5)=0.0\n",
      "epoch 1/50, loss=30.0, w=0.29999998211860657\n",
      "epoch 3/50, loss=15.660187721252441, w=0.7717499136924744\n",
      "epoch 5/50, loss=8.17471694946289, w=1.1125893592834473\n",
      "epoch 7/50, loss=4.2672529220581055, w=1.358845829963684\n",
      "epoch 9/50, loss=2.227532148361206, w=1.5367661714553833\n",
      "epoch 11/50, loss=1.1627856492996216, w=1.6653136014938354\n",
      "epoch 13/50, loss=0.6069811582565308, w=1.758189082145691\n",
      "epoch 15/50, loss=0.3168478012084961, w=1.825291633605957\n",
      "epoch 17/50, loss=0.1653965264558792, w=1.873773217201233\n",
      "epoch 19/50, loss=0.08633805811405182, w=1.9088011980056763\n",
      "epoch 21/50, loss=0.0450688973069191, w=1.934108853340149\n",
      "epoch 23/50, loss=0.02352631464600563, w=1.952393651008606\n",
      "epoch 25/50, loss=0.012280836701393127, w=1.9656044244766235\n",
      "epoch 27/50, loss=0.0064106592908501625, w=1.9751492738723755\n",
      "epoch 29/50, loss=0.0033464201260358095, w=1.982045292854309\n",
      "epoch 31/50, loss=0.0017468547448515892, w=1.987027645111084\n",
      "epoch 33/50, loss=0.0009118800517171621, w=1.9906275272369385\n",
      "epoch 35/50, loss=0.0004760062729474157, w=1.9932283163070679\n",
      "epoch 37/50, loss=0.0002484779979567975, w=1.9951075315475464\n",
      "epoch 39/50, loss=0.00012970640091225505, w=1.9964652061462402\n",
      "epoch 41/50, loss=6.770494655938819e-05, w=1.9974461793899536\n",
      "epoch 43/50, loss=3.5343608033144847e-05, w=1.998154878616333\n",
      "epoch 45/50, loss=1.844714643084444e-05, w=1.9986668825149536\n",
      "epoch 47/50, loss=9.631531611375976e-06, w=1.9990367889404297\n",
      "epoch 49/50, loss=5.027383849665057e-06, w=1.9993040561676025\n",
      "prediction after training : f(5)=10.0\n"
     ]
    }
   ],
   "source": [
    "#replacing gradient calculation \n",
    "# f=w*x\n",
    "#f=2*x\n",
    "import torch\n",
    "X=torch.tensor([1,2,3,4],dtype=torch.float32)\n",
    "y=torch.tensor([2,4,6,8],dtype=torch.float32)\n",
    "w=torch.tensor(0.0,dtype=torch.float32,requires_grad=True)\n",
    "\n",
    "#model prediction\n",
    "\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "print(f'prediction before training : f(5)={forward(5)}')\n",
    "#Training\n",
    "lr=0.01\n",
    "n_iters=50\n",
    "loss=nn.MSELoss()\n",
    "optimizer=torch.optim.SGD([w],lr=lr,)\n",
    "for epoch in range(n_iters):\n",
    "    #prediction\n",
    "    y_predicted=forward(X)\n",
    "    #loss\n",
    "    l=loss(y,y_predicted)\n",
    "    #gradient=backwardpass \n",
    "    l.backward()\n",
    "    #update weights\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad() # zero the gradients after updating weights to avoid accumulation of gradients from previous epoch  # important for the next epoch.\n",
    "\n",
    "    if epoch%2==0:\n",
    "        print(f'epoch {epoch+1}/{n_iters}, loss={l}, w={w}')\n",
    "print(f'prediction after training : f(5)={forward(5):.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "prediction before training : f(tensor([5.]))=tensor([-4.5452], grad_fn=<ViewBackward0>)\n",
      "epoch 1,: w=-0.310, loss=67.93379974\n",
      "epoch 3,: w=0.379, loss=32.71066284\n",
      "epoch 5,: w=0.857, loss=15.75181675\n",
      "epoch 7,: w=1.189, loss=7.58664703\n",
      "epoch 9,: w=1.419, loss=3.65534902\n",
      "epoch 11,: w=1.579, loss=1.76252365\n",
      "epoch 13,: w=1.690, loss=0.85115743\n",
      "epoch 15,: w=1.768, loss=0.41233349\n",
      "epoch 17,: w=1.821, loss=0.20102456\n",
      "epoch 19,: w=1.859, loss=0.09925579\n",
      "epoch 21,: w=1.885, loss=0.05022815\n",
      "epoch 23,: w=1.903, loss=0.02659379\n",
      "epoch 25,: w=1.915, loss=0.01518589\n",
      "epoch 27,: w=1.924, loss=0.00966493\n",
      "epoch 29,: w=1.931, loss=0.00697871\n",
      "epoch 31,: w=1.935, loss=0.00565766\n",
      "epoch 33,: w=1.938, loss=0.00499422\n",
      "epoch 35,: w=1.941, loss=0.00464773\n",
      "epoch 37,: w=1.942, loss=0.00445417\n",
      "epoch 39,: w=1.944, loss=0.00433453\n",
      "epoch 41,: w=1.945, loss=0.00425085\n",
      "epoch 43,: w=1.945, loss=0.00418474\n",
      "epoch 45,: w=1.946, loss=0.00412743\n",
      "epoch 47,: w=1.947, loss=0.00407465\n",
      "epoch 49,: w=1.947, loss=0.00402434\n",
      "epoch 51,: w=1.947, loss=0.00397553\n",
      "epoch 53,: w=1.948, loss=0.00392775\n",
      "epoch 55,: w=1.948, loss=0.00388074\n",
      "epoch 57,: w=1.949, loss=0.00383437\n",
      "epoch 59,: w=1.949, loss=0.00378861\n",
      "epoch 61,: w=1.949, loss=0.00374342\n",
      "epoch 63,: w=1.950, loss=0.00369879\n",
      "epoch 65,: w=1.950, loss=0.00365469\n",
      "epoch 67,: w=1.950, loss=0.00361111\n",
      "epoch 69,: w=1.950, loss=0.00356805\n",
      "epoch 71,: w=1.951, loss=0.00352551\n",
      "epoch 73,: w=1.951, loss=0.00348348\n",
      "epoch 75,: w=1.951, loss=0.00344195\n",
      "epoch 77,: w=1.952, loss=0.00340092\n",
      "epoch 79,: w=1.952, loss=0.00336037\n",
      "epoch 81,: w=1.952, loss=0.00332032\n",
      "epoch 83,: w=1.952, loss=0.00328074\n",
      "epoch 85,: w=1.953, loss=0.00324161\n",
      "epoch 87,: w=1.953, loss=0.00320297\n",
      "epoch 89,: w=1.953, loss=0.00316479\n",
      "epoch 91,: w=1.954, loss=0.00312706\n",
      "epoch 93,: w=1.954, loss=0.00308977\n",
      "epoch 95,: w=1.954, loss=0.00305294\n",
      "epoch 97,: w=1.954, loss=0.00301653\n",
      "epoch 99,: w=1.955, loss=0.00298058\n",
      "prediction after training : f(5.0)=9.9\n"
     ]
    }
   ],
   "source": [
    "# replacing manually impmeneted pytorch function with nn\n",
    "\n",
    "#replacing gradient calculation \n",
    "# f=w*x\n",
    "#f=2*x\n",
    "import torch\n",
    "X=torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\n",
    "y=torch.tensor([[2],[4],[6],[8]],dtype=torch.float32)\n",
    "\n",
    "n_sample,n_features =X.shape\n",
    "print(n_sample,n_features)\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "# model=nn.Linear(input_size, output_size)\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "model=LinearRegression(input_size,output_size)\n",
    "\n",
    "x_test=torch.tensor([5],dtype=torch.float32)\n",
    "print(f'prediction before training : f({x_test})={model(x_test)}'.format())\n",
    "#Training\n",
    "lr=0.01\n",
    "n_iters=100\n",
    "loss=nn.MSELoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=lr,)\n",
    "loss_value=[]\n",
    "for epoch in range(n_iters):\n",
    "    model.train()\n",
    "    #prediction\n",
    "    y_predicted=model(X)\n",
    "    #loss\n",
    "    l=loss(y,y_predicted)\n",
    "    loss_value.append(l.item())\n",
    "    #gradient=backwardpass \n",
    "    l.backward()\n",
    "    #update weights\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad() # zero the gradients after updating weights to avoid accumulation of gradients from previous epoch  # important for the next epoch.\n",
    "\n",
    "    if epoch%2==0:\n",
    "        [w,b]=model.parameters()\n",
    "        print(f'epoch {epoch+1},: w={w[0][0].item():.3f}, loss={l:.8f}')\n",
    "print(f'prediction after training : f({x_test[0]})={model(x_test).item():.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2774197f1a0>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(\"Training loss\")\n",
    "plt.plot(loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
